{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "The purpose of this notebook is to implement data preparation and detailed analysis specifically for the chosen modeling task: predict car make from technical attributes (no price or insurance info)\n",
    "\n",
    "## Modeling Task\n",
    "The motivating objective for this modeling task is to compare the efficacy of two different approaches for characterising \"feature importance\" for Random Forest classifiers.  A similar analysis is demonstrated here: https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html \n",
    "I will perform a similar set of tasks, but I will do so on the 1985 Auto Imports database.\n",
    "\n",
    "Upon a cursory reading of the description of the data set (https://www.openml.org/d/9), I noticed (based on intuition) that many of the technical attributes are probably strongly correlated due to constrains of physics, engineering, manufacturing, etc.:\n",
    "\n",
    "15. engine-type: dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n",
    "16. num-of-cylinders: eight, five, four, six, three, twelve, two.\n",
    "17. engine-size: continuous from 61 to 326.\n",
    "18. fuel-system: 1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n",
    "19. bore: continuous from 2.54 to 3.94.\n",
    "20. stroke: continuous from 2.07 to 4.17.\n",
    "21. compression-ratio: continuous from 7 to 23.\n",
    "22. horsepower: continuous from 48 to 288.\n",
    "23. peak-rpm: continuous from 4150 to 6600.\n",
    "\n",
    "If, in fact, many of these features are correlated, it may have interesting impacts on the experiment.  It may be necessary to take measures to reduce the number of correlated features.\n",
    "\n",
    "I'm specifically intersted in doing a demonstration of a multi-class classifier.  Therefore, I will use the \"make\" attribute (attribute 3) as the response variable.\n",
    "\n",
    "Fore model features, initially, I will consider using all features other than the monetary-related features (1. symboling; 2. normalized-losses; 26. price)\n",
    "\n",
    "## TODO\n",
    "- Consider custom feature encoding\n",
    "- Transform data into supervised learning structure: reponse vector + design matrix\n",
    "- Make partitions for Train, Test, Validation (note, there are only 205 rows in whole data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FIGSIZE = (14, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = fetch_openml(data_id=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Combine target data and rest of 'data'\n",
    "data_values = np.concatenate(\n",
    "    (np.reshape(full_data['target'], (len(full_data['target']), 1)), full_data['data']), \n",
    "    axis=1)\n",
    "# - Concatenate column names too\n",
    "all_cols = ['symboling']\n",
    "all_cols.extend(full_data['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame(data_values, columns=all_cols).infer_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205 entries, 0 to 204\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   symboling          205 non-null    object \n",
      " 1   normalized-losses  164 non-null    float64\n",
      " 2   make               205 non-null    float64\n",
      " 3   fuel-type          205 non-null    float64\n",
      " 4   aspiration         205 non-null    float64\n",
      " 5   num-of-doors       203 non-null    float64\n",
      " 6   body-style         205 non-null    float64\n",
      " 7   drive-wheels       205 non-null    float64\n",
      " 8   engine-location    205 non-null    float64\n",
      " 9   wheel-base         205 non-null    float64\n",
      " 10  length             205 non-null    float64\n",
      " 11  width              205 non-null    float64\n",
      " 12  height             205 non-null    float64\n",
      " 13  curb-weight        205 non-null    float64\n",
      " 14  engine-type        205 non-null    float64\n",
      " 15  num-of-cylinders   205 non-null    float64\n",
      " 16  engine-size        205 non-null    float64\n",
      " 17  fuel-system        205 non-null    float64\n",
      " 18  bore               201 non-null    float64\n",
      " 19  stroke             201 non-null    float64\n",
      " 20  compression-ratio  205 non-null    float64\n",
      " 21  horsepower         203 non-null    float64\n",
      " 22  peak-rpm           203 non-null    float64\n",
      " 23  city-mpg           205 non-null    float64\n",
      " 24  highway-mpg        205 non-null    float64\n",
      " 25  price              201 non-null    float64\n",
      "dtypes: float64(25), object(1)\n",
      "memory usage: 41.8+ KB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Data Analysis and Curation\n",
    "\n",
    "- Due to the goals of the experiment, let's simplify our lives by removing all rows from classes that are severaly undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine-location\n",
      "num-of-doors\n",
      "body-style\n",
      "peak-rpm\n",
      "aspiration\n",
      "fuel-type\n",
      "width\n",
      "horsepower\n",
      "bore\n",
      "highway-mpg\n",
      "length\n",
      "fuel-system\n",
      "engine-type\n",
      "curb-weight\n",
      "height\n",
      "city-mpg\n",
      "drive-wheels\n",
      "stroke\n",
      "num-of-cylinders\n",
      "wheel-base\n",
      "compression-ratio\n",
      "engine-size\n"
     ]
    }
   ],
   "source": [
    "response_col = 'make'\n",
    "# - Easier to list the features to be ignored than to list those to be included\n",
    "ignore_feature_cols = [response_col, 'symboling', 'normalized-losses', 'price']\n",
    "feature_cols = list(set(full_df.columns) - set(ignore_feature_cols))\n",
    "for col in feature_cols:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove \"make\" values that have too few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_examples_count = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0    32\n",
       "12.0    18\n",
       "8.0     17\n",
       "5.0     13\n",
       "11.0    13\n",
       "18.0    12\n",
       "20.0    12\n",
       "13.0    11\n",
       "21.0    11\n",
       "4.0      9\n",
       "9.0      8\n",
       "2.0      8\n",
       "14.0     7\n",
       "1.0      7\n",
       "17.0     6\n",
       "15.0     5\n",
       "6.0      4\n",
       "3.0      3\n",
       "0.0      3\n",
       "7.0      3\n",
       "16.0     2\n",
       "10.0     1\n",
       "Name: make, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_value_counts = full_df[response_col].value_counts()\n",
    "response_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.0, 12.0, 8.0, 5.0, 11.0, 18.0, 20.0, 13.0, 21.0, 4.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_response_values = response_value_counts[response_value_counts >= min_examples_count].keys().tolist()\n",
    "valid_response_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 26)\n"
     ]
    }
   ],
   "source": [
    "modeling_df = full_df[full_df[response_col].isin(valid_response_values)]\n",
    "print(modeling_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove rows that have NaN values for any feature cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 26)\n"
     ]
    }
   ],
   "source": [
    "modeling_df = modeling_df[~modeling_df[feature_cols].isna().any(axis=1)]\n",
    "print(modeling_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 142 entries, 21 to 204\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   symboling          142 non-null    object \n",
      " 1   normalized-losses  129 non-null    float64\n",
      " 2   make               142 non-null    float64\n",
      " 3   fuel-type          142 non-null    float64\n",
      " 4   aspiration         142 non-null    float64\n",
      " 5   num-of-doors       142 non-null    float64\n",
      " 6   body-style         142 non-null    float64\n",
      " 7   drive-wheels       142 non-null    float64\n",
      " 8   engine-location    142 non-null    float64\n",
      " 9   wheel-base         142 non-null    float64\n",
      " 10  length             142 non-null    float64\n",
      " 11  width              142 non-null    float64\n",
      " 12  height             142 non-null    float64\n",
      " 13  curb-weight        142 non-null    float64\n",
      " 14  engine-type        142 non-null    float64\n",
      " 15  num-of-cylinders   142 non-null    float64\n",
      " 16  engine-size        142 non-null    float64\n",
      " 17  fuel-system        142 non-null    float64\n",
      " 18  bore               142 non-null    float64\n",
      " 19  stroke             142 non-null    float64\n",
      " 20  compression-ratio  142 non-null    float64\n",
      " 21  horsepower         142 non-null    float64\n",
      " 22  peak-rpm           142 non-null    float64\n",
      " 23  city-mpg           142 non-null    float64\n",
      " 24  highway-mpg        142 non-null    float64\n",
      " 25  price              142 non-null    float64\n",
      "dtypes: float64(25), object(1)\n",
      "memory usage: 30.0+ KB\n"
     ]
    }
   ],
   "source": [
    "modeling_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    modeling_df[feature_cols], \n",
    "    modeling_df[response_col], \n",
    "    test_size=0.33, \n",
    "    stratify=modeling_df[response_col], \n",
    "    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 95 entries, 34 to 62\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   engine-location    95 non-null     float64\n",
      " 1   num-of-doors       95 non-null     float64\n",
      " 2   body-style         95 non-null     float64\n",
      " 3   peak-rpm           95 non-null     float64\n",
      " 4   aspiration         95 non-null     float64\n",
      " 5   fuel-type          95 non-null     float64\n",
      " 6   width              95 non-null     float64\n",
      " 7   horsepower         95 non-null     float64\n",
      " 8   bore               95 non-null     float64\n",
      " 9   highway-mpg        95 non-null     float64\n",
      " 10  length             95 non-null     float64\n",
      " 11  fuel-system        95 non-null     float64\n",
      " 12  engine-type        95 non-null     float64\n",
      " 13  curb-weight        95 non-null     float64\n",
      " 14  height             95 non-null     float64\n",
      " 15  city-mpg           95 non-null     float64\n",
      " 16  drive-wheels       95 non-null     float64\n",
      " 17  stroke             95 non-null     float64\n",
      " 18  num-of-cylinders   95 non-null     float64\n",
      " 19  wheel-base         95 non-null     float64\n",
      " 20  compression-ratio  95 non-null     float64\n",
      " 21  engine-size        95 non-null     float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 17.1 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 47 entries, 95 to 65\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   engine-location    47 non-null     float64\n",
      " 1   num-of-doors       47 non-null     float64\n",
      " 2   body-style         47 non-null     float64\n",
      " 3   peak-rpm           47 non-null     float64\n",
      " 4   aspiration         47 non-null     float64\n",
      " 5   fuel-type          47 non-null     float64\n",
      " 6   width              47 non-null     float64\n",
      " 7   horsepower         47 non-null     float64\n",
      " 8   bore               47 non-null     float64\n",
      " 9   highway-mpg        47 non-null     float64\n",
      " 10  length             47 non-null     float64\n",
      " 11  fuel-system        47 non-null     float64\n",
      " 12  engine-type        47 non-null     float64\n",
      " 13  curb-weight        47 non-null     float64\n",
      " 14  height             47 non-null     float64\n",
      " 15  city-mpg           47 non-null     float64\n",
      " 16  drive-wheels       47 non-null     float64\n",
      " 17  stroke             47 non-null     float64\n",
      " 18  num-of-cylinders   47 non-null     float64\n",
      " 19  wheel-base         47 non-null     float64\n",
      " 20  compression-ratio  47 non-null     float64\n",
      " 21  engine-size        47 non-null     float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 8.4 KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0    22\n",
       "12.0    12\n",
       "11.0     9\n",
       "5.0      9\n",
       "20.0     8\n",
       "8.0      8\n",
       "18.0     8\n",
       "21.0     7\n",
       "13.0     7\n",
       "4.0      5\n",
       "Name: make, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0    10\n",
       "12.0     6\n",
       "20.0     4\n",
       "5.0      4\n",
       "8.0      4\n",
       "11.0     4\n",
       "18.0     4\n",
       "13.0     4\n",
       "21.0     4\n",
       "4.0      3\n",
       "Name: make, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- This is such a small data set that after filtering out very low occurence classes and doing a train-test split, there are very few samples left for the test set.  This will make it quite difficult to interpret the results of the experiment.  \n",
    " - Specifically, I'm hoping to interpret the difference in Performance-Recall metrics among a set of models (Random Forest models with different features being ignored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
